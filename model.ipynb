{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Convolution2D, Lambda, MaxPooling2D, Dropout, Cropping2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_loc = \"./own_data/IMG/\"\n",
    "info = pd.read_csv(\"own_data/driving_log.csv\", names=['path_c', 'path_l', 'path_r', 'angle', 'throttle', 'break', 'speed'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change name of images\n",
    "\n",
    "info['rel_path_c'] = info[\"path_c\"].str.split(\"\\\\\").apply(lambda x: rel_loc + str(x[-1]))\n",
    "info['rel_path_l'] = info[\"path_l\"].str.split(\"\\\\\").apply(lambda x: rel_loc + str(x[-1]))\n",
    "info['rel_path_r'] = info[\"path_r\"].str.split(\"\\\\\").apply(lambda x: rel_loc + str(x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe\n",
    "train_data, val_data = train_test_split(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize(image):\n",
    "    return cv2.resize(image, (int(1/2*320), int(1/2*160)), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "def recolor(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def load_data(data, batch_size=10, include_side=True):\n",
    "    num_samples = data.shape[0]\n",
    "    #while True:\n",
    "    angles = []\n",
    "    images = []\n",
    "    #for offset in range(0, num_samples, batch_size):\n",
    "        #for index, row in data.iloc[offset:offset+batch_size].iterrows():\n",
    "    for index, row in data.iterrows():\n",
    "        image = recolor(resize(cv2.imread(row[\"rel_path_c\"])))\n",
    "        image_flipped = np.fliplr(image)\n",
    "        measurement = float(row[\"angle\"])\n",
    "        measurement_flipped = -measurement\n",
    "\n",
    "        images.append(image)\n",
    "        angles.append(measurement)\n",
    "\n",
    "        images.append(image_flipped)\n",
    "        angles.append(measurement_flipped)\n",
    "\n",
    "        if include_side:\n",
    "            correction = 0.2 # this is a parameter to tune\n",
    "            measurement_left = measurement + correction\n",
    "            measurement_right = measurement - correction\n",
    "            images.append(recolor(resize(cv2.imread(row[\"rel_path_l\"]))))\n",
    "            angles.append(measurement_left)\n",
    "            images.append(recolor(resize(cv2.imread(row[\"rel_path_r\"]))))\n",
    "            angles.append(measurement_right)\n",
    "                \n",
    "    return shuffle(np.array(images), np.array(angles))\n",
    "# In the end, I didnt use generator, as AWS could fit the data into memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val, y_val   = load_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16372 samples, validate on 5460 samples\n",
      "Epoch 1/5\n",
      "16372/16372 [==============================] - 38s - loss: 0.0320 - val_loss: 0.0240\n",
      "Epoch 2/5\n",
      "16372/16372 [==============================] - 35s - loss: 0.0254 - val_loss: 0.0234\n",
      "Epoch 3/5\n",
      "16372/16372 [==============================] - 35s - loss: 0.0229 - val_loss: 0.0225\n",
      "Epoch 4/5\n",
      "16372/16372 [==============================] - 35s - loss: 0.0216 - val_loss: 0.0217\n",
      "Epoch 5/5\n",
      "16372/16372 [==============================] - 35s - loss: 0.0209 - val_loss: 0.0210\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((35,15), (0,0)), input_shape=(80,160,3)))\n",
    "#model.add(Lambda(lambda x: tf.image.rgb_to_grayscale(x)))\n",
    "model.add(Lambda(lambda x: x/255.0-0.5))\n",
    "model.add(Convolution2D(12, 5, 5, activation=\"relu\"))\n",
    "model.add(Convolution2D(24, 5, 5, activation=\"relu\"))\n",
    "model.add(Convolution2D(48, 5, 5, activation=\"relu\"))\n",
    "model.add(Convolution2D(64, 3, 3, activation=\"relu\"))\n",
    "model.add(Convolution2D(64, 3, 3, activation=\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50,  activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,  activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "#model.fit_generator(train_gen,\n",
    "#                    samples_per_epoch = train_data.shape[0] * 3, # This is because of the 3 camera images\n",
    "#                    validation_data=val_gen,\n",
    "#                    nb_val_samples= val_data.shape[0]*3, nb_epoch=10, verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, nb_epoch=5, validation_data=(X_val, y_val))\n",
    "\n",
    "model.save(\"model.h5\")\n",
    "#exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
